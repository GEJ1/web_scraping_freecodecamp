{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "KcHglp06hnfy"
      ],
      "authorship_tag": "ABX9TyOFJ8pXqNGKSmKc7RFivfbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GEJ1/web_scraping_freecodecamp/blob/main/web_scraping_freeCodeCamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFbPvfyu3yaS"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://d33wubrfki0l68.cloudfront.net/774b60156d8f103170dc66f3ad10310941114653/da262/img/fcc_secondary_large.svg\" width=\"600\" height=\"auto\"/>\n",
        "\n",
        "# **Web scraping con Python**\n",
        "\n",
        "## *Material complementario del curso dictado por [Gustavo Juantorena](https://github.com/GEJ1) para **freeCodecamp** en español.*\n",
        "\n",
        "### **Link a la web de práctica: https://scrapepark.org/spanish/**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T6lp5_w9Gi0"
      },
      "source": [
        "<center>\n",
        "\n",
        "### **Importante**: Los cambios que hagan en este cuaderno de Colab no se guardarán, lo ideal sería que hagan una copia del mismo en sus respectivas cuentas de Google Drive de la siguiente manera:\n",
        "\n",
        "### *Archivo > Guardar una copia en drive*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hoja de ruta**\n",
        "\n",
        "## 1. Pedidos HTTP con **Requests**\n",
        "## 2. Uso basico de **APIs**\n",
        "## 3. Web Scraping con **Beautiful Soup**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UE_kUe2dlbbF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UQcVg3CKSi1"
      },
      "source": [
        "# **Pedidos HTTP con requests**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32ZIp-taK6PE"
      },
      "source": [
        "import requests\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc1hU64tLv-v"
      },
      "source": [
        "# Hacemos un pedido a la página de wikipedia\n",
        "URL = 'https://es.wikipedia.org/'\n",
        "\n",
        "# Guardamos el objeto que nos devuelve\n",
        "respuesta = requests.get(URL)\n",
        "\n",
        "# print(f'Tipo de Objeto: {type(respuesta)} \\n')\n",
        "# print(f'Código de estado: {respuesta.status_code} \\n')\n",
        "print(f'Data: {respuesta.text} \\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1AgS5HxPIPg"
      },
      "source": [
        "## **Headers**\n",
        "\n",
        "Una serie de datos que acompañan al pedido. Para saber más: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers\n",
        "\n",
        "\n",
        "El objeto `Response` de `requests` tiene los siguientes elementos principales:\n",
        "\n",
        "* `.text`\n",
        "* `.content`\n",
        "* `.json()`\n",
        "* `.status_code`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBifgfShPKlV"
      },
      "source": [
        "URL = 'https://scrapeme.org'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
        "}\n",
        "respuesta = requests.get(URL, headers=headers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "respuesta.text"
      ],
      "metadata": {
        "id": "sbA4w5LXhb-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamoslo en la práctica utilizando la siguiente web: http://httpbin.org/headers (útil para testear pedidos HTTP).\n"
      ],
      "metadata": {
        "id": "6yF0A4Nl6K2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'http://httpbin.org/headers'\n",
        "resp = requests.get(URL)\n",
        "\n",
        "print('Respuesta sin headers:')\n",
        "print(resp.text)"
      ],
      "metadata": {
        "id": "yGvs4upI6KLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Respuesta con headers:')\n",
        "nuestros_headers = {\n",
        "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36'\n",
        "    }\n",
        "resp_con_headers = requests.get(URL, headers = nuestros_headers)\n",
        "print(resp_con_headers.text)"
      ],
      "metadata": {
        "id": "X94bg5Lfh1Uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFVDnesOKZ7N"
      },
      "source": [
        "# **Uso basico de APIs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd60DCLFhhvP"
      },
      "source": [
        "### Uso de API de manera directa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3rq7-cOLHuV"
      },
      "source": [
        "[Sunset and sunrise times API](https://sunrise-sunset.org/api)\n",
        "\n",
        "**Sirve para obtener la hora del amanecer y el ocaso de un determinado día**\n",
        "\n",
        "*Parámetros:*\n",
        "\n",
        "\n",
        "*  **lat** (float): Latitud en grados decimales(Obligatorio)\n",
        "*  **lng** (float): Longitud en grados decimales (obligatorio)\n",
        "*  **date** (string): Fecha en formato AAAA-MM-DD (opcional, por defecto usa el día actual)\n",
        "\n",
        "*Estructura de la query:*\n",
        "\n",
        "`https://api.sunrise-sunset.org/json?`\n",
        "\n",
        "`lat=36.7201600`\n",
        "\n",
        "`&`\n",
        "\n",
        "`lng=-4.4203400`\n",
        "\n",
        "`&`\n",
        "\n",
        "`date=2021-07-26`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos los parametros de nuestra query\n",
        "latitud = -34.6\n",
        "longitud = -58.4\n",
        "fecha = '1816-07-09' # AAAA-MM-DD"
      ],
      "metadata": {
        "id": "EIFWdHPVJsEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hacemos el pedido y guardamos la respuesta en una nueva variable\n",
        "respuesta_sunset = requests.get(f'https://api.sunrise-sunset.org/json?lat={latitud}&lng={longitud}&date={fecha}')"
      ],
      "metadata": {
        "id": "oe0bMEQBJubx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(respuesta_sunset)"
      ],
      "metadata": {
        "id": "1KBTJWoYllvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para des-serializar el objeto (que era tipo 'HTTPResponse') y cargarlo como json\n",
        "datos_sunset = respuesta_sunset.json()\n",
        "print(datos_sunset)\n"
      ],
      "metadata": {
        "id": "dZkY8OHKJxFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(datos_sunset)\n",
        "datos_sunset.keys()"
      ],
      "metadata": {
        "id": "7kr6nPiQl1gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluamos el status del pedido\n",
        "sunset_status = datos_sunset['status']\n",
        "print(f'Status: {sunset_status}')"
      ],
      "metadata": {
        "id": "Z8lcUaepJ2IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos_sunset['results']['sunset']"
      ],
      "metadata": {
        "id": "AVf-wnSKmAKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Podemos ver su contenido ya que es son diccionarios anidados:\n",
        "sunset = datos_sunset['results']['sunset']\n",
        "print(f'El {fecha} el sol se ocultó a las {sunset} (UTC)')"
      ],
      "metadata": {
        "id": "vDCpwey_J6J1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c10bda-1433-4882-b9d3-c6e4516cc2aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El 1816-07-09 el sol se ocultó a las 8:58:27 PM (UTC)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tambien podriamos iterar sobre sus claves\n",
        "print(\"Iterando data_sunset['results']:\")\n",
        "for elemento in datos_sunset['results']:\n",
        "  print(elemento)"
      ],
      "metadata": {
        "id": "_1N7IJIiKIIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcHglp06hnfy"
      },
      "source": [
        "### **Uso de API por medio de una librería: Wikipedia**\n",
        "\n",
        "Wikipedia-API es un *wrapper* de Python fácil de usar para la API de Wikipedia. Admite la extracción de textos, secciones, enlaces, categorías, traducciones, etc.\n",
        "\n",
        "Repositorio: https://github.com/martin-majlis/Wikipedia-API\n",
        "\n",
        "Documentación: https://wikipedia-api.readthedocs.io/en/latest/README.html\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqWcjExWiihS"
      },
      "source": [
        "# Instalamos el paquete porque no viene con Colab\n",
        "!pip3 install --force-reinstall -v  \"wikipedia-api==0.5.8\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WTgRAA3sjdG"
      },
      "source": [
        "# Ahora si podemos importarlo\n",
        "import wikipediaapi\n",
        "\n",
        "#chequear versión\n",
        "print(wikipediaapi.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLY7a8imigip"
      },
      "source": [
        "# Instanciamos la clase wikipediaapi y utilizamos el metodo Wikipedia con el parametro de idioma\n",
        "IDIOMA = 'es'\n",
        "wiki_wiki = wikipediaapi.Wikipedia(IDIOMA)\n",
        "\n",
        "# Usamos el metodo page para y hacemos un pedido con una palabra clave\n",
        "PALABRA_CLAVE = 'programación'\n",
        "wikipedia_programacion = wiki_wiki.page(PALABRA_CLAVE)\n",
        "\n",
        "print(f'wikipedia_programacion es un objeto de tipo: \\n \\n{type(wikipedia_programacion)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK5pdTsYivt8"
      },
      "source": [
        "# Resumen\n",
        "print(wikipedia_programacion.title)\n",
        "print(' ')\n",
        "print(wikipedia_programacion.summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhukUmpni1Au",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f13f9e8f-b52e-4f05-f041-a16af857b0c8"
      },
      "source": [
        "# Url completa\n",
        "print(wikipedia_programacion.fullurl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://es.wikipedia.org/wiki/Programaci%C3%B3n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ZRRKjv8b4e"
      },
      "source": [
        "# **BeautifulSoup**\n",
        "Documentación oficial: https://beautiful-soup-4.readthedocs.io/en/latest/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGXRo8BWtIDc"
      },
      "source": [
        "## **Generalidades**\n",
        "\n",
        "Vamos a practicar con https://scrapepark.org/spanish/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ],
      "metadata": {
        "id": "DemLUNc7d_W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Versiones\n",
        "import bs4 # Solo para el chequeo\n",
        "print(\"Versión de BeautifulSoup:\",bs4.__version__)\n",
        "print(\"Versión de requests:\", requests.__version__)"
      ],
      "metadata": {
        "id": "T5XplMATeVXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En caso de no tener la versión que se usa en este curso\n",
        "!pip3 install beautifulsoup4==4.11.2\n",
        "!pip3 install requests==2.27.1"
      ],
      "metadata": {
        "id": "OOJxCTeb2Sys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLnDRuoftSDX"
      },
      "source": [
        "# Empezamos el scraping\n",
        "\n",
        "# 1. Obtener el HTML\n",
        "URL_BASE = 'https://scrapepark.org/spanish/'\n",
        "pedido_obtenido = requests.get(URL_BASE)\n",
        "html_obtenido = pedido_obtenido.text\n",
        "\n",
        "# 2. \"Parsear\" ese HTML\n",
        "soup = BeautifulSoup(html_obtenido, \"html.parser\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(soup)"
      ],
      "metadata": {
        "id": "O1lXQ39Ao64s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **El método `find()`**\n",
        "\n",
        "Nos permite quedarnos con la información asociada a una etiqueta de HTML"
      ],
      "metadata": {
        "id": "AS5-q5L-eLZ_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo7AkWAhh23W"
      },
      "source": [
        "primer_h2 = soup.find('h2')\n",
        "print(primer_h2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solo el texto\n",
        "print(primer_h2.text)\n",
        "\n",
        "# equivalente a:\n",
        "# print(soup.h2.text)"
      ],
      "metadata": {
        "id": "jP47spPBiYfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **El método `find_all()`**\n",
        "\n",
        "Busca **TODOS** los elementos de la página con esa etiqueta y devuelve una \"lista\" que los contiene (en realidad devuelve un objeto de la clase *bs4.element.ResultSet*)."
      ],
      "metadata": {
        "id": "MFO_d99OeavG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h2_todos = soup.find_all('h2')\n",
        "print(h2_todos)"
      ],
      "metadata": {
        "id": "6YlYosUFmc66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az5VWD8qh5XP"
      },
      "source": [
        "# ARGUMENTOS\n",
        "# Si usamos el parametro limit = 1, emulamos al metodo find\n",
        "h2_uno_solo = soup.find_all('h2',limit=1)\n",
        "print(h2_uno_solo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_pjutuZh9wz"
      },
      "source": [
        "# Podemos iterar sobre el objeto\n",
        "for seccion in h2_todos:\n",
        "  print(seccion.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get_text() para más funcionalidades\n",
        "for seccion in h2_todos:\n",
        "  print(seccion.get_text(strip=True))"
      ],
      "metadata": {
        "id": "Vm5TjiHV4lCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Utilizando atributos de las etiquetas**\n",
        "\n"
      ],
      "metadata": {
        "id": "H936ZYAerBXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase\n",
        "divs = soup.find_all('div', class_ = \"heading-container heading-center\")\n",
        "\n",
        "for div in divs:\n",
        "  print(div)\n",
        "  print(\" \")"
      ],
      "metadata": {
        "id": "GyPbqaejp4is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVxip8F0iEYA"
      },
      "source": [
        "# Todas las etiquetas que tengan el atributo \"src\"\n",
        "src_todos = soup.find_all(src=True)\n",
        "\n",
        "for elemento in src_todos:\n",
        "  if elemento['src'].endswith(\".jpg\"):\n",
        "    print(elemento)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ejercicio: Bajar todas las imagenes!\n",
        "\n",
        "url_imagenes = []\n",
        "\n",
        "for i, imagen in enumerate(src_todos):\n",
        "\n",
        "  if imagen['src'].endswith('png'):\n",
        "\n",
        "    print(imagen['src'])\n",
        "    r = requests.get(f\"https://scrapepark.org/{imagen['src']}\")\n",
        "\n",
        "    with open(f'imagen_{i}.png', 'wb') as f:\n",
        "      f.write(r.content)"
      ],
      "metadata": {
        "id": "pm4eVZCW6jjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tablas**"
      ],
      "metadata": {
        "id": "nxurw0jxiwm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('iframe')[0]['src']"
      ],
      "metadata": {
        "id": "YyqtIpXMw9sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Información de tablas\n",
        "\n",
        "URL_BASE = 'https://scrapeme.org/spanish'\n",
        "URL_TABLA = soup.find_all('iframe')[0]['src']\n",
        "\n",
        "request_tabla = requests.get(f'{URL_BASE}/{URL_TABLA}')\n",
        "\n",
        "html_tabla = request_tabla.text\n",
        "soup_tabla = BeautifulSoup(html_tabla, \"html.parser\")\n",
        "soup_tabla.find('table')\n",
        "\n",
        "productos_faltantes = soup_tabla.find_all(['th', 'td'], attrs={'style':'color: red;'})\n",
        "productos_faltantes = [talle.text for talle in productos_faltantes]\n",
        "\n",
        "print(productos_faltantes)"
      ],
      "metadata": {
        "id": "qvrCha4Qwz1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "divs = soup.find_all('div', class_='detail-box')\n",
        "productos = []\n",
        "precios = []\n",
        "\n",
        "for div in divs:\n",
        "  if (div.h6 is not None) and ('Patineta' in div.h5.text):\n",
        "    producto = div.h5.get_text(strip=True)\n",
        "    precio = div.h6.get_text(strip=True).replace('$', '')\n",
        "    # Se puede agregar filtros\n",
        "    print(f'producto: {producto:<16} | precio: {precio}')\n",
        "    productos.append(producto)\n",
        "    precios.append(precio)"
      ],
      "metadata": {
        "id": "OWDrRpN14mkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precios"
      ],
      "metadata": {
        "id": "fFOxFOsRretL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "productos"
      ],
      "metadata": {
        "id": "guSnGHLIrcp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cambios que dependen de la URL**"
      ],
      "metadata": {
        "id": "2QphGTciOnZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL_BASE = \"https://scrapepark.org/spanish/contact\"\n",
        "\n",
        "for i in range(1,3):\n",
        "  URL_FINAL = f\"{URL_BASE}{i}\"\n",
        "  print(URL_FINAL)\n",
        "  r = requests.get(URL_FINAL)\n",
        "  soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "  print(soup.h5.text)"
      ],
      "metadata": {
        "id": "zW_XZj6TOqar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Datos que no sabemos en que parte de la página se encuentran**"
      ],
      "metadata": {
        "id": "mRw2htzlj9Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expresiones regulares\n",
        "import re\n",
        "\n",
        "# 1. Obtener el HTML\n",
        "URL_BASE = 'https://scrapeme.org/spanish'\n",
        "pedido_obtenido = requests.get(URL_BASE)\n",
        "html_obtenido = pedido_obtenido.text\n",
        "\n",
        "# 2. \"Parsear\" ese HTML\n",
        "soup = BeautifulSoup(html_obtenido, \"html.parser\")\n",
        "\n",
        "telefonos = soup.find_all(string=re.compile(\"\\d+-\\d+-\\d+\"))\n",
        "telefonos"
      ],
      "metadata": {
        "id": "SClwgT23kDb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Moviéndonos por el árbol**\n",
        "\n",
        "Para saber más: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#searching-the-tree"
      ],
      "metadata": {
        "id": "1Sq_ZX03oPQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "copyrights = soup.find_all(string=re.compile(\"©\"))\n",
        "copyrights[0]"
      ],
      "metadata": {
        "id": "QqzYlp0jnxAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "primer_copyright = copyrights[0]\n",
        "primer_copyright.parent"
      ],
      "metadata": {
        "id": "BYaiCi_tuSek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Otro ejemplo con elementos al mismo nivel\n",
        "menu = soup.find(string=re.compile(\"MENÚ\"))\n",
        "# menu.parent\n",
        "menu.parent.find_next_siblings()"
      ],
      "metadata": {
        "id": "GDlAB53SuDf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Comentario sobre excepciones**\n",
        "https://docs.python.org/es/3/tutorial/errors.html"
      ],
      "metadata": {
        "id": "IrUz6btarWj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "strings_a_buscar = [\"MENÚ\", \"©\", \"carpincho\", \"Patineta\"]\n",
        "\n",
        "for string in strings_a_buscar:\n",
        "  try:\n",
        "    resultado = soup.find(string=re.compile(string))\n",
        "    print(resultado.text)\n",
        "  except AttributeError:\n",
        "    print(f\"El string '{string}' no fue encontrado\")"
      ],
      "metadata": {
        "id": "iSgBLoDFrs3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Almacenamiento de los datos**"
      ],
      "metadata": {
        "id": "rnyPln5D4dsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "productos.insert(0, \"productos\")\n",
        "precios.insert(0, \"precios\")\n",
        "# datos = dict(zip(productos, precios))"
      ],
      "metadata": {
        "id": "MizBsJA3gCQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos = dict(zip(productos, precios))"
      ],
      "metadata": {
        "id": "qXUvdB2Mx5WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datos.items()"
      ],
      "metadata": {
        "id": "tsss7E0Ny4mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "with open('datos.csv','w') as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerows(datos.items())"
      ],
      "metadata": {
        "id": "YcIts8u56tA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BONUS!**\n",
        "Algunos ejercicios para seguir practicando:\n",
        "\n",
        "1. Las patinetas que salgan menos que $68\n",
        "2. Las patinetas que en su nombre tengan un numero mayor a 3\n",
        "3. Traer cualquier texto de la pagina que tenga la palabra descuento u oferta.\n",
        "5. Generar un archivo .csv con dos columnas: Una conteniendo el nombre del cliente y otra su testimonio."
      ],
      "metadata": {
        "id": "oEHvwn9Xw0sf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eCpy9QPW8Dwd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}